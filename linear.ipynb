{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from deepsplines.ds_modules import dsnn\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import wandb\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "torch.set_default_dtype(torch.float)\n",
    "device = torch.device('cpu' if torch.backends.mps.is_available() else 'mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Deepsline California Housing\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"Deepline Linear\",\n",
    "    \"dataset\": \"California Housing\",\n",
    "    \"epochs\": 1000,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    " \n",
    "data = fetch_california_housing()\n",
    "print(data.feature_names)\n",
    " \n",
    "X, y = data.data, data.target\n",
    "# Do more data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = {\n",
    "    'size': 51, #knots k+2\n",
    "    'range_': 6,\n",
    "    'init': 'leaky_relu',\n",
    "    'save_memory': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSplines(dsnn.DSModule):\n",
    "    def __init__(self,opt_params,epochs,lr):\n",
    "\n",
    "        super(DeepSplines,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "                        nn.Linear(8, 24),\n",
    "                        dsnn.DeepBSpline('fc', 24, **opt_params),\n",
    "                        nn.Linear(24, 12),\n",
    "                        dsnn.DeepBSpline('fc', 12, **opt_params),\n",
    "                        nn.Linear(12, 8),\n",
    "                        dsnn.DeepBSpline('fc', 8, **opt_params),\n",
    "                        nn.Linear(8, 1)\n",
    "                    )\n",
    "        self.initialization(opt_params['init'], init_type='He')\n",
    "        self.num_params = self.get_num_params()\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.train()\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters_deepspline(), lr=self.lr)\n",
    "        for epoch in range(self.epochs):\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = self.forward(X)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            wandb.log({\"loss\": loss.item()}, step=epoch)\n",
    "            if epoch % 100 == 0:\n",
    "                print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "        return loss.item()\n",
    "    \n",
    "    def predict(self,X,y):\n",
    "        self.eval()\n",
    "        criterion = nn.MSELoss()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.forward(X)\n",
    "        loss= criterion(y_pred, y)\n",
    "        #print('test loss: {}'.format(loss.item()))\n",
    "        return loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fmnggi6a) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>1.19497</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">true-bee-5</strong> at: <a href='https://wandb.ai/animax_sg/Deepsline%20California%20Housing/runs/fmnggi6a' target=\"_blank\">https://wandb.ai/animax_sg/Deepsline%20California%20Housing/runs/fmnggi6a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230512_051841-fmnggi6a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fmnggi6a). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/animeshsengupta/Work_Directory/DACSS/STAT690DS/Project/wandb/run-20230512_052011-ncsvmn38</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/animax_sg/Deepsline%20California%20Housing/runs/ncsvmn38' target=\"_blank\">polished-pine-6</a></strong> to <a href='https://wandb.ai/animax_sg/Deepsline%20California%20Housing' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/animax_sg/Deepsline%20California%20Housing' target=\"_blank\">https://wandb.ai/animax_sg/Deepsline%20California%20Housing</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/animax_sg/Deepsline%20California%20Housing/runs/ncsvmn38' target=\"_blank\">https://wandb.ai/animax_sg/Deepsline%20California%20Housing/runs/ncsvmn38</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss: 2048.640625\n",
      "Epoch 100: train loss: 262.302978515625\n",
      "Epoch 200: train loss: 24.150646209716797\n",
      "Epoch 300: train loss: 3.652357339859009\n",
      "Epoch 400: train loss: 2.0325727462768555\n",
      "Epoch 500: train loss: 1.7896946668624878\n",
      "Epoch 600: train loss: 1.6957175731658936\n",
      "Epoch 700: train loss: 1.638900876045227\n",
      "Epoch 800: train loss: 1.597341537475586\n",
      "Epoch 900: train loss: 1.5654112100601196\n",
      "Epoch 1000: train loss: 1.5399304628372192\n",
      "Epoch 1100: train loss: 1.5191593170166016\n",
      "Epoch 1200: train loss: 1.5016937255859375\n",
      "Epoch 1300: train loss: 1.4867788553237915\n",
      "Epoch 1400: train loss: 1.4739432334899902\n",
      "Epoch 1500: train loss: 1.4625310897827148\n",
      "Epoch 1600: train loss: 1.4523838758468628\n",
      "Epoch 1700: train loss: 1.4435290098190308\n",
      "Epoch 1800: train loss: 1.4354238510131836\n",
      "Epoch 1900: train loss: 1.4280016422271729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectTimeout), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "model=DeepSplines(opt_params,epochs=2000,lr=1e-4)\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Deepsline California Housing\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"Deepline Linear\",\n",
    "    \"dataset\": \"California Housing\",\n",
    "    \"epochs\": 1000,\n",
    "    }\n",
    ")\n",
    "wandb.watch(model,log= \"all\",log_freq=10)\n",
    "loss_tr=model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
